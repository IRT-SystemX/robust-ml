

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>robustML.advertrain.dependencies.autoattack &mdash; Robustness Platform 0.1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=a58bc63e"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            Robustness Platform
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../guidelines.html">ðŸ’¡ Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../architecture.html">ðŸŽ¡ Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../changelog.html">ðŸ”„ Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules.html">ðŸ”Ž Package robust-ml</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Robustness Platform</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">robustML.advertrain.dependencies.autoattack</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for robustML.advertrain.dependencies.autoattack</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Taken from https://github.com/fra31/auto-attack</span>

<span class="sd">MIT License</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>


<div class="viewcode-block" id="L0_norm">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.L0_norm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">L0_norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the L0 norm of a tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The L0 norm of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">!=</span> <span class="mf">0.</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>



<div class="viewcode-block" id="L1_norm">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.L1_norm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">L1_norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the L1 norm of a tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input tensor.</span>
<span class="sd">        keepdim (bool, optional): Whether to keep the dimensions or not. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The L1 norm of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">keepdim</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">z</span></div>



<div class="viewcode-block" id="L2_norm">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.L2_norm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">L2_norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">keepdim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the L2 norm of a tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input tensor.</span>
<span class="sd">        keepdim (bool, optional): Whether to keep the dimensions or not. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The L2 norm of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">keepdim</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">z</span></div>



<div class="viewcode-block" id="L1_projection">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.L1_projection">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">L1_projection</span><span class="p">(</span><span class="n">x2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">eps1</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Project a point onto an L1 ball.</span>

<span class="sd">    Args:</span>
<span class="sd">        x2 (torch.Tensor): Center of the L1 ball (bs x input_dim).</span>
<span class="sd">        y2 (torch.Tensor): Current perturbation (x2 + y2 is the point to be projected).</span>
<span class="sd">        eps1 (float): Radius of the L1 ball.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Delta such that ||y2 + delta||_1 &lt;= eps1 and 0 &lt;= x2 + y2 + delta &lt;= 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y2</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">y2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">bs</span><span class="p">,</span> <span class="n">indbs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">u</span><span class="p">,</span> <span class="n">l</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bs2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">bs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">bs</span><span class="o">.</span><span class="n">device</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">inu</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">indbs</span> <span class="o">&lt;</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">size1</span> <span class="o">=</span> <span class="n">inu</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s1</span> <span class="o">=</span> <span class="o">-</span><span class="n">u</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">eps1</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">c5</span> <span class="o">=</span> <span class="n">s1</span> <span class="o">+</span> <span class="n">c</span> <span class="o">&lt;</span> <span class="mi">0</span>
    <span class="n">c2</span> <span class="o">=</span> <span class="n">c5</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s1</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">((</span><span class="n">bs2</span> <span class="o">-</span> <span class="n">bs</span><span class="p">)</span> <span class="o">*</span> <span class="n">size1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">c2</span><span class="o">.</span><span class="n">nelement</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">ub</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">lb</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">bs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">nitermax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">bs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()))</span>
        <span class="n">counter2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">lb</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">counter</span> <span class="o">&lt;</span> <span class="n">nitermax</span><span class="p">:</span>
            <span class="n">counter4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">lb</span> <span class="o">+</span> <span class="n">ub</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span>
            <span class="n">counter2</span> <span class="o">=</span> <span class="n">counter4</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span>
            <span class="n">c8</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="n">counter2</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="n">c2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span>
            <span class="n">ind3</span> <span class="o">=</span> <span class="n">c8</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">ind32</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">c8</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind3</span><span class="o">.</span><span class="n">nelement</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">lb</span><span class="p">[</span><span class="n">ind3</span><span class="p">]</span> <span class="o">=</span> <span class="n">counter4</span><span class="p">[</span><span class="n">ind3</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">ind32</span><span class="o">.</span><span class="n">nelement</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ub</span><span class="p">[</span><span class="n">ind32</span><span class="p">]</span> <span class="o">=</span> <span class="n">counter4</span><span class="p">[</span><span class="n">ind32</span><span class="p">]</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">lb2</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">s</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="n">lb2</span><span class="p">]</span> <span class="o">-</span> <span class="n">c</span><span class="p">[</span><span class="n">c2</span><span class="p">])</span> <span class="o">/</span> <span class="n">size1</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="n">lb2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">bs2</span><span class="p">[</span><span class="n">c2</span><span class="p">,</span> <span class="n">lb2</span><span class="p">]</span>
        <span class="n">d</span><span class="p">[</span><span class="n">c2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="n">u</span><span class="p">[</span><span class="n">c2</span><span class="p">],</span> <span class="n">alpha</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="o">-</span><span class="n">l</span><span class="p">[</span><span class="n">c2</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div>



<div class="viewcode-block" id="APGDAttack">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">APGDAttack</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the Auto-PGD (Auto Projected Gradient Descent) attack method.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model (Callable): A function representing the forward pass of the model to be attacked.</span>
<span class="sd">        n_iter (int): Number of iterations for the attack.</span>
<span class="sd">        norm (str): The type of norm for the attack (&#39;Linf&#39;, &#39;L2&#39;, &#39;L1&#39;).</span>
<span class="sd">        n_restarts (int): Number of random restarts for the attack.</span>
<span class="sd">        eps (float): The maximum perturbation amount allowed.</span>
<span class="sd">        seed (int): Random seed for reproducibility.</span>
<span class="sd">        loss (str): Type of loss function to use (&#39;ce&#39; for cross-entropy, &#39;dlr&#39;).</span>
<span class="sd">        eot_iter (int): Number of iterations for Expectation over Transformation.</span>
<span class="sd">        rho (float): Parameter for adjusting step size.</span>
<span class="sd">        topk (Optional[float]): Parameter for controlling the sparsity of the attack.</span>
<span class="sd">        verbose (bool): If True, prints verbose output during the attack.</span>
<span class="sd">        device (Optional[torch.device]): The device on which to perform computations.</span>
<span class="sd">        use_largereps (bool): If True, uses larger epsilon values in initial iterations.</span>
<span class="sd">        is_tf_model (bool): If True, indicates the model is a TensorFlow model.</span>

<span class="sd">    Methods:</span>
<span class="sd">        init_hyperparam(x): Initializes hyperparameters based on the input data.</span>
<span class="sd">        check_oscillation(...): Checks for oscillation in the optimization process.</span>
<span class="sd">        check_shape(x): Ensures the input has the expected shape.</span>
<span class="sd">        normalize(x): Normalizes the input tensor.</span>
<span class="sd">        lp_norm(x): Computes the Lp norm of the input.</span>
<span class="sd">        dlr_loss(x, y): Computes the Deep Learning Robustness (DLR) loss.</span>
<span class="sd">        attack_single_run(x, y, x_init=None): Performs a single run of the attack.</span>
<span class="sd">        perturb(x, y=None, best_loss=False, x_init=None): Generates adversarial examples for the given inputs.</span>
<span class="sd">        decr_eps_pgd(x, y, epss, iters, use_rs=True): Performs PGD with decreasing epsilon values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">predict</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
            <span class="n">n_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
            <span class="n">norm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;Linf&#39;</span><span class="p">,</span>
            <span class="n">n_restarts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">loss</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;ce&#39;</span><span class="p">,</span>
            <span class="n">eot_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">rho</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">.75</span><span class="p">,</span>
            <span class="n">topk</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">use_largereps</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">is_tf_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the APGDAttack object with the given parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            predict: A callable representing the forward pass of the model.</span>
<span class="sd">            n_iter: Number of iterations for the attack.</span>
<span class="sd">            norm: The norm type for the attack (&#39;Linf&#39;, &#39;L2&#39;, &#39;L1&#39;).</span>
<span class="sd">            n_restarts: Number of random restarts for the attack.</span>
<span class="sd">            eps: The maximum perturbation amount allowed.</span>
<span class="sd">            seed: Random seed for reproducibility.</span>
<span class="sd">            loss: Type of loss function to use.</span>
<span class="sd">            eot_iter: Number of iterations for Expectation over Transformation.</span>
<span class="sd">            rho: Parameter for adjusting step size.</span>
<span class="sd">            topk: Parameter for controlling sparsity in &#39;L1&#39; norm.</span>
<span class="sd">            verbose: If True, enables verbose output.</span>
<span class="sd">            device: The device on which to perform computations.</span>
<span class="sd">            use_largereps: If True, uses larger epsilon values initially.</span>
<span class="sd">            is_tf_model: If True, indicates a TensorFlow model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">predict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_restarts</span> <span class="o">=</span> <span class="n">n_restarts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eot_iter</span> <span class="o">=</span> <span class="n">eot_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thr_decr</span> <span class="o">=</span> <span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">topk</span> <span class="o">=</span> <span class="n">topk</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_rs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_largereps</span> <span class="o">=</span> <span class="n">use_largereps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_orig</span> <span class="o">=</span> <span class="n">n_iter</span> <span class="o">+</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps_orig</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">+</span> <span class="mf">0.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_model</span> <span class="o">=</span> <span class="n">is_tf_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span> <span class="o">=</span> <span class="kc">None</span>


<div class="viewcode-block" id="APGDAttack.init_hyperparam">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.init_hyperparam">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_hyperparam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes various hyperparameters based on the input data.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Linf&#39;</span><span class="p">,</span> <span class="s1">&#39;L2&#39;</span><span class="p">,</span> <span class="s1">&#39;L1&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orig_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># set parameters for checkpoints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_2</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.22</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_min</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.06</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size_decr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.03</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="APGDAttack.check_oscillation">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.check_oscillation">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">check_oscillation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">y5</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">k3</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks for oscillation in the optimization process to adjust step sizes.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor.</span>
<span class="sd">            j (int): Current iteration index.</span>
<span class="sd">            k (int): The number of steps to look back for oscillation.</span>
<span class="sd">            y5 (torch.Tensor): The tensor of losses.</span>
<span class="sd">            k3 (float, optional): Threshold parameter for oscillation. Defaults to 0.75.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Tensor indicating if oscillation is detected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">counter5</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">j</span> <span class="o">-</span> <span class="n">counter5</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span> <span class="o">-</span> <span class="n">counter5</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">t</span> <span class="o">&lt;=</span> <span class="n">k</span> <span class="o">*</span> <span class="n">k3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">t</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span></div>


<div class="viewcode-block" id="APGDAttack.check_shape">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.check_shape">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">check_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ensures the input tensor has the correct shape.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The reshaped tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="APGDAttack.normalize">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.normalize">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Normalizes the input tensor based on the specified norm type.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor to be normalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The normalized tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;Linf&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">))</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L2&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">))</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">))</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span></div>


<div class="viewcode-block" id="APGDAttack.lp_norm">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.lp_norm">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">lp_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Lp norm of the input tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The computed Lp norm of the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L2&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">))</span></div>


<div class="viewcode-block" id="APGDAttack.dlr_loss">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.dlr_loss">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">dlr_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Deep Learning Robustness (DLR) loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The logits from the model.</span>
<span class="sd">            y (torch.Tensor): The target labels.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The computed DLR loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_sorted</span><span class="p">,</span> <span class="n">ind_sorted</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">ind_sorted</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_sorted</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">ind</span> <span class="o">-</span> <span class="n">x_sorted</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
            <span class="mf">1.</span> <span class="o">-</span> <span class="n">ind</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_sorted</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_sorted</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)</span></div>


<div class="viewcode-block" id="APGDAttack.attack_single_run">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.attack_single_run">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">attack_single_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs a single run of the attack.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input data (clean images).</span>
<span class="sd">            y (torch.Tensor): The target labels.</span>
<span class="sd">            x_init (Optional[torch.Tensor]): Initial starting point for the attack.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing the best perturbed inputs,</span>
<span class="sd">            the accuracy tensor, the loss tensor, and the best adversarial examples found.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;Linf&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L2&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">L1_projection</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
            <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">t</span> <span class="o">+</span> <span class="n">delta</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">x_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x_init</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[custom init] L1 perturbation </span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">x_adv</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>
        <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="n">x_best</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">x_best_adv</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">loss_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss_best_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">acc_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">loss_best_steps</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_model</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;ce&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;ce-targeted-cfts&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="o">-</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;dlr&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlr_loss</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;dlr-targeted&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlr_loss_targeted</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;ce-targeted&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss_targeted</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;unknowkn loss&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;ce&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_logits_loss_grad_xent</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;dlr&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_logits_loss_grad_dlr</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;dlr-targeted&#39;</span><span class="p">:</span>
                <span class="n">criterion_indiv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_logits_loss_grad_target</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;unknowkn loss&#39;</span><span class="p">)</span>

        <span class="n">x_adv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eot_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_model</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_adv</span><span class="p">)</span>
                    <span class="n">loss_indiv</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_indiv</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">grad</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">x_adv</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logits</span><span class="p">,</span> <span class="n">loss_indiv</span><span class="p">,</span> <span class="n">grad_curr</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">x_adv</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logits</span><span class="p">,</span> <span class="n">loss_indiv</span><span class="p">,</span> <span class="n">grad_curr</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">x_adv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span><span class="p">)</span>
                <span class="n">grad</span> <span class="o">+=</span> <span class="n">grad_curr</span>

        <span class="n">grad</span> <span class="o">/=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eot_iter</span><span class="p">)</span>
        <span class="n">grad_best</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span>
        <span class="n">acc_steps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">+</span> <span class="mi">0</span>
        <span class="n">loss_best</span> <span class="o">=</span> <span class="n">loss_indiv</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">2.</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Linf&#39;</span><span class="p">,</span> <span class="s1">&#39;L2&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;L1&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="mf">2e-2</span>
        <span class="n">step_size</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">*</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">)])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">x_adv_old</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_2</span> <span class="o">+</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">.04</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">n_fts</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_dim</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">x_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">topk</span> <span class="o">=</span> <span class="mf">.2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">sp_old</span> <span class="o">=</span> <span class="n">n_fts</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">topk</span> <span class="o">=</span> <span class="n">L0_norm</span><span class="p">(</span><span class="n">x_adv</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_fts</span> <span class="o">/</span> <span class="mf">1.5</span>
                <span class="n">sp_old</span> <span class="o">=</span> <span class="n">L0_norm</span><span class="p">(</span><span class="n">x_adv</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>

            <span class="n">adasp_redstep</span> <span class="o">=</span> <span class="mf">1.5</span>
            <span class="n">adasp_minstep</span> <span class="o">=</span> <span class="mf">10.</span>

        <span class="n">counter3</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">loss_best_last_check</span> <span class="o">=</span> <span class="n">loss_best</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">reduced_last_check</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">loss_best</span><span class="p">)</span>
        <span class="n">n_reduced</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">n_fts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
            <span class="c1"># gradient step</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">grad2</span> <span class="o">=</span> <span class="n">x_adv</span> <span class="o">-</span> <span class="n">x_adv_old</span>
                <span class="n">x_adv_old</span> <span class="o">=</span> <span class="n">x_adv</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">a</span> <span class="o">=</span> <span class="mf">0.75</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;Linf&#39;</span><span class="p">:</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">x_adv</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x_adv_1</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">),</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
                        <span class="n">x_adv</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x_adv</span><span class="p">)</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">grad2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">),</span>
                        <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">),</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L2&#39;</span><span class="p">:</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">x_adv</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lp_norm</span><span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">x_adv</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x_adv</span><span class="p">)</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">grad2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lp_norm</span><span class="p">(</span><span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span><span class="p">:</span>
                    <span class="n">grad_topk</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">topk_curr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">topk</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_fts</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">n_fts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                    <span class="n">grad_topk</span> <span class="o">=</span> <span class="n">grad_topk</span><span class="p">[</span><span class="n">u</span><span class="p">,</span> <span class="n">topk_curr</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">sparsegrad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">grad_topk</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">x_adv</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">sparsegrad</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">sparsegrad</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
                    <span class="n">delta_u</span> <span class="o">=</span> <span class="n">x_adv_1</span> <span class="o">-</span> <span class="n">x</span>
                    <span class="n">delta_p</span> <span class="o">=</span> <span class="n">L1_projection</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">delta_u</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
                    <span class="n">x_adv_1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">delta_u</span> <span class="o">+</span> <span class="n">delta_p</span>
                <span class="n">x_adv</span> <span class="o">=</span> <span class="n">x_adv_1</span> <span class="o">+</span> <span class="mf">0.</span>
            <span class="c1"># get gradient</span>
            <span class="n">x_adv</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eot_iter</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_model</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
                        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_adv</span><span class="p">)</span>
                        <span class="n">loss_indiv</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_indiv</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

                    <span class="n">grad</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">x_adv</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">logits</span><span class="p">,</span> <span class="n">loss_indiv</span><span class="p">,</span> <span class="n">grad_curr</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">x_adv</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logits</span><span class="p">,</span> <span class="n">loss_indiv</span><span class="p">,</span> <span class="n">grad_curr</span> <span class="o">=</span> <span class="n">criterion_indiv</span><span class="p">(</span><span class="n">x_adv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_target</span><span class="p">)</span>
                    <span class="n">grad</span> <span class="o">+=</span> <span class="n">grad_curr</span>

            <span class="n">grad</span> <span class="o">/=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eot_iter</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
            <span class="n">acc_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">+</span> <span class="mi">0</span>
            <span class="n">ind_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">x_best_adv</span><span class="p">[</span><span class="n">ind_pred</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_adv</span><span class="p">[</span><span class="n">ind_pred</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">str_stats</span> <span class="o">=</span> <span class="s1">&#39; - step size: </span><span class="si">{:.5f}</span><span class="s1"> - topk: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">step_size</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">topk</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="n">n_fts</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;L1&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[m] iteration: </span><span class="si">{}</span><span class="s1"> - best loss: </span><span class="si">{:.6f}</span><span class="s1"> - robust accuracy: </span><span class="si">{:.2%}{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">i</span><span class="p">,</span> <span class="n">loss_best</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">acc</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">str_stats</span><span class="p">))</span>

            <span class="c1"># check step size</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">y1</span> <span class="o">=</span> <span class="n">loss_indiv</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">loss_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">+</span> <span class="mi">0</span>
                <span class="n">ind</span> <span class="o">=</span> <span class="p">(</span><span class="n">y1</span> <span class="o">&gt;</span> <span class="n">loss_best</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">x_best</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_adv</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">grad_best</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">loss_best</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">y1</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">+</span> <span class="mi">0</span>
                <span class="n">loss_best_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_best</span> <span class="o">+</span> <span class="mi">0</span>
                <span class="n">counter3</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">counter3</span> <span class="o">==</span> <span class="n">k</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Linf&#39;</span><span class="p">,</span> <span class="s1">&#39;L2&#39;</span><span class="p">]:</span>
                        <span class="n">fl_oscillation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_oscillation</span><span class="p">(</span><span class="n">loss_steps</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">loss_best</span><span class="p">,</span> <span class="n">k3</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">thr_decr</span><span class="p">)</span>
                        <span class="n">fl_reduce_no_impr</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">reduced_last_check</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="n">loss_best_last_check</span> <span class="o">&gt;=</span> <span class="n">loss_best</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                        <span class="n">fl_oscillation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">fl_oscillation</span><span class="p">,</span> <span class="n">fl_reduce_no_impr</span><span class="p">)</span>
                        <span class="n">reduced_last_check</span> <span class="o">=</span> <span class="n">fl_oscillation</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                        <span class="n">loss_best_last_check</span> <span class="o">=</span> <span class="n">loss_best</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                        <span class="k">if</span> <span class="n">fl_oscillation</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">ind_fl_osc</span> <span class="o">=</span> <span class="p">(</span><span class="n">fl_oscillation</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                            <span class="n">step_size</span><span class="p">[</span><span class="n">ind_fl_osc</span><span class="p">]</span> <span class="o">/=</span> <span class="mf">2.0</span>
                            <span class="n">n_reduced</span> <span class="o">=</span> <span class="n">fl_oscillation</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

                            <span class="n">x_adv</span><span class="p">[</span><span class="n">ind_fl_osc</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_best</span><span class="p">[</span><span class="n">ind_fl_osc</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                            <span class="n">grad</span><span class="p">[</span><span class="n">ind_fl_osc</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_best</span><span class="p">[</span><span class="n">ind_fl_osc</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">size_decr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_min</span><span class="p">)</span>

                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;L1&#39;</span><span class="p">:</span>
                        <span class="n">sp_curr</span> <span class="o">=</span> <span class="n">L0_norm</span><span class="p">(</span><span class="n">x_best</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
                        <span class="n">fl_redtopk</span> <span class="o">=</span> <span class="p">(</span><span class="n">sp_curr</span> <span class="o">/</span> <span class="n">sp_old</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">.95</span>
                        <span class="n">topk</span> <span class="o">=</span> <span class="n">sp_curr</span> <span class="o">/</span> <span class="n">n_fts</span> <span class="o">/</span> <span class="mf">1.5</span>
                        <span class="n">step_size</span><span class="p">[</span><span class="n">fl_redtopk</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>
                        <span class="n">step_size</span><span class="p">[</span><span class="o">~</span><span class="n">fl_redtopk</span><span class="p">]</span> <span class="o">/=</span> <span class="n">adasp_redstep</span>
                        <span class="n">step_size</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">/</span> <span class="n">adasp_minstep</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
                        <span class="n">sp_old</span> <span class="o">=</span> <span class="n">sp_curr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                        <span class="n">x_adv</span><span class="p">[</span><span class="n">fl_redtopk</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_best</span><span class="p">[</span><span class="n">fl_redtopk</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                        <span class="n">grad</span><span class="p">[</span><span class="n">fl_redtopk</span><span class="p">]</span> <span class="o">=</span> <span class="n">grad_best</span><span class="p">[</span><span class="n">fl_redtopk</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                    <span class="n">counter3</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">x_best</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">loss_best</span><span class="p">,</span> <span class="n">x_best_adv</span><span class="p">)</span></div>



<div class="viewcode-block" id="APGDAttack.perturb">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.perturb">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">perturb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">best_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">x_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates adversarial examples for the given inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Clean images.</span>
<span class="sd">            y (Optional[torch.Tensor]): Clean labels. If None, predicted labels are used.</span>
<span class="sd">            best_loss (bool, optional): If True, returns points with highest loss. Defaults to False.</span>
<span class="sd">            x_init (Optional[torch.Tensor]): Initial starting point for the attack.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Adversarial examples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ce&#39;</span><span class="p">,</span> <span class="s1">&#39;dlr&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_hyperparam</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tf_model</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">adv</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">!=</span> <span class="s1">&#39;ce-targeted&#39;</span><span class="p">:</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">!=</span> <span class="n">y</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1e10</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------------------------- &#39;</span><span class="p">,</span> <span class="s1">&#39;running </span><span class="si">{}</span><span class="s1">-attack with epsilon </span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">),</span> <span class="s1">&#39;--------------------------&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;initial accuracy: </span><span class="si">{:.2%}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_largereps</span><span class="p">:</span>
            <span class="n">epss</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps_orig</span><span class="p">,</span> <span class="mf">2.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps_orig</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps_orig</span><span class="p">]</span>
            <span class="n">iters</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_orig</span><span class="p">,</span> <span class="mf">.3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_orig</span><span class="p">,</span>
                <span class="mf">.4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_orig</span><span class="p">]</span>
            <span class="n">iters</span> <span class="o">=</span> <span class="p">[</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">iters</span><span class="p">]</span>
            <span class="n">iters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_orig</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">iters</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># make sure to use the given iterations</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;using schedule [</span><span class="si">{}</span><span class="s1">x</span><span class="si">{}</span><span class="s1">]&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;+&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">epss</span><span class="p">]),</span> <span class="s1">&#39;+&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">iters</span><span class="p">])))</span>

        <span class="n">startt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">best_loss</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">counter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_restarts</span><span class="p">):</span>
                <span class="n">ind_to_fool</span> <span class="o">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind_to_fool</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">ind_to_fool</span> <span class="o">=</span> <span class="n">ind_to_fool</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">ind_to_fool</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">x_to_fool</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind_to_fool</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="n">y_to_fool</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind_to_fool</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_largereps</span><span class="p">:</span>
                        <span class="n">res_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attack_single_run</span><span class="p">(</span><span class="n">x_to_fool</span><span class="p">,</span> <span class="n">y_to_fool</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">res_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decr_eps_pgd</span><span class="p">(</span><span class="n">x_to_fool</span><span class="p">,</span> <span class="n">y_to_fool</span><span class="p">,</span> <span class="n">epss</span><span class="p">,</span> <span class="n">iters</span><span class="p">)</span>
                    <span class="n">best_curr</span><span class="p">,</span> <span class="n">acc_curr</span><span class="p">,</span> <span class="n">loss_curr</span><span class="p">,</span> <span class="n">adv_curr</span> <span class="o">=</span> <span class="n">res_curr</span>
                    <span class="n">ind_curr</span> <span class="o">=</span> <span class="p">(</span><span class="n">acc_curr</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                    <span class="n">acc</span><span class="p">[</span><span class="n">ind_to_fool</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">adv</span><span class="p">[</span><span class="n">ind_to_fool</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]]</span> <span class="o">=</span> <span class="n">adv_curr</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;restart </span><span class="si">{}</span><span class="s1"> - robust accuracy: </span><span class="si">{:.2%}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">counter</span><span class="p">,</span> <span class="n">acc</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span>
                            <span class="s1">&#39;- cum. time: </span><span class="si">{:.1f}</span><span class="s1"> s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">startt</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">adv</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">adv_best</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">loss_best</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">counter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_restarts</span><span class="p">):</span>
                <span class="n">best_curr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss_curr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attack_single_run</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                <span class="n">ind_curr</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_curr</span> <span class="o">&gt;</span> <span class="n">loss_best</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">adv_best</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_curr</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.</span>
                <span class="n">loss_best</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_curr</span><span class="p">[</span><span class="n">ind_curr</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;restart </span><span class="si">{}</span><span class="s1"> - loss: </span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">loss_best</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
            <span class="k">return</span> <span class="n">adv_best</span></div>


<div class="viewcode-block" id="APGDAttack.decr_eps_pgd">
<a class="viewcode-back" href="../../../../robustML.advertrain.dependencies.html#robustML.advertrain.dependencies.autoattack.APGDAttack.decr_eps_pgd">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">decr_eps_pgd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">epss</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">iters</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">use_rs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs PGD with decreasing epsilon values.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input data.</span>
<span class="sd">            y (torch.Tensor): The target labels.</span>
<span class="sd">            epss (list): List of epsilon values to use in the attack.</span>
<span class="sd">            iters (list): List of iteration counts corresponding to each epsilon value.</span>
<span class="sd">            use_rs (bool, optional): If True, uses random start. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing the final perturbed inputs,</span>
<span class="sd">            the accuracy tensor, the loss tensor, and the best adversarial examples found.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">epss</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">iters</span><span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;L1&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_rs</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_rs</span><span class="p">:</span>
            <span class="n">x_init</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_init</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x_init</span> <span class="o">+=</span> <span class="n">L1_projection</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_init</span> <span class="o">-</span> <span class="n">x</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">epss</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">eps_target</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">epss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total iter: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">iters</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">eps</span><span class="p">,</span> <span class="n">niter</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">epss</span><span class="p">,</span> <span class="n">iters</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;using eps: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">eps</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">niter</span> <span class="o">+</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">+</span> <span class="mf">0.</span>
            <span class="c1">#</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">x_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">x_init</span> <span class="o">+=</span> <span class="n">L1_projection</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_init</span> <span class="o">-</span> <span class="n">x</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span>
            <span class="n">x_init</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">x_adv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attack_single_run</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_init</span><span class="o">=</span><span class="n">x_init</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x_init</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">x_adv</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, IRT SystemX.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>